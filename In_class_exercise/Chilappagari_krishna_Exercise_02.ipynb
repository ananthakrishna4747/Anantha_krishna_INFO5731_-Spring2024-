{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananthakrishna4747/Anantha_krishna_INFO5731_-Spring2024-/blob/main/In_class_exercise/Chilappagari_krishna_Exercise_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DymRJbxDBCnf"
      },
      "source": [
        "# **INFO5731 In-class Exercise 2**\n",
        "\n",
        "The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."
      ],
      "metadata": {
        "id": "FBKvD6O_TY6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your answer here\n",
        "\n",
        "''' I once thought to implement analysis on recent cricket worldcup and i thought if i could predict the match ups\n",
        "#based on previous stats, how a batsmen performs against a given bowler and vice versa, if it gets implemented\n",
        "correctly by collecting data, fitting a model, then it would havily impact the betting world or even such apps\n",
        "like \"Dream11\", \"My11Circle\". So i went on to gather data from cricbuzz, use it to fit the model and succeeded\n",
        "in doing so. This is the idea i had in mind '''"
      ],
      "metadata": {
        "id": "cikVKDXdTbzE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "71eb191c-9cc5-4ddf-e2de-05f134724341"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I once thought to implement analysis on recent cricket worldcup and i thought if i could predict the match ups\\n#based on previous stats, how a batsmen performs against a given bowler and vice versa, if it gets implemented\\ncorrectly by collecting data, fitting a model, then it would havily impact the betting world or even such apps\\nlike \"Dream11\", \"My11Circle\". So i went on to gather data from cricbuzz, use it to fit the model and succeeded\\nin doing so. This is the idea i had in mind '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 (10 Points)\n",
        "Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."
      ],
      "metadata": {
        "id": "E9RqrlwdTfvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def extract_batting_data(series_id, match_id):\n",
        "\n",
        "    URL = 'https://www.espncricinfo.com/series/'+ str(series_id) + '/scorecard/' + str(match_id)\n",
        "    page = requests.get(URL)\n",
        "    bs = BeautifulSoup(page.content, 'lxml')\n",
        "\n",
        "    table_body=bs.find_all('tbody')\n",
        "    batsmen_df = pd.DataFrame(columns=[\"Name\",\"Desc\",\"Runs\", \"Balls\", \"4s\", \"6s\", \"SR\", \"Team\"])\n",
        "    for i, table in enumerate(table_body[0:4:2]):\n",
        "        rows = table.find_all('tr')\n",
        "        for row in rows[::2]:\n",
        "          cols = row.find_all('td')\n",
        "          if len(cols) < 2:  # Check if cols has at least 2 elements\n",
        "              continue\n",
        "          cols = [x.text.strip() for x in cols]\n",
        "          if cols[0] == 'Extras':\n",
        "              continue\n",
        "          if len(cols) > 7:\n",
        "              new_row = pd.Series(\n",
        "                  [re.sub(r\"\\W+\", ' ', cols[0].split(\"(c)\")[0]).strip(), cols[1],\n",
        "                  cols[2], cols[3], cols[5], cols[6], cols[7], i+1],\n",
        "                  index=batsmen_df.columns\n",
        "              )\n",
        "          else:\n",
        "              new_row = pd.Series(\n",
        "                  [re.sub(r\"\\W+\", ' ', cols[0].split(\"(c)\")[0]).strip(), cols[1],\n",
        "                  0, 0, 0, 0, 0, i+1],\n",
        "                  index=batsmen_df.columns\n",
        "              )\n",
        "          batsmen_df = pd.concat([batsmen_df, new_row.to_frame().T], ignore_index=True)\n",
        "\n",
        "\n",
        "    for i in range(min(2, len(bs.find_all(\"tfoot\")))):\n",
        "        dnb_row = bs.find_all(\"tfoot\")[i].find_all(\"div\")\n",
        "        for c in dnb_row:\n",
        "            dnb_cols = c.find_all('span')\n",
        "            dnb = [x.text.strip().split(\"(c)\")[0] for x in dnb_cols]\n",
        "            dnb = filter(lambda item: item, [re.sub(r\"\\W+\", ' ', x).strip() for x in dnb])\n",
        "            for dnb_batsman in dnb:\n",
        "                batsmen_df = batsmen_df.append(pd.Series([dnb_batsman, \"DNB\", 0, 0, 0, 0, 0, i+1], index=batsmen_df.columns), ignore_index=True)\n",
        "\n",
        "\n",
        "    return batsmen_df\n",
        "\n",
        "# Example usage\n",
        "extract_batting_data(series_id=8048, match_id=1136561)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "_Kl956M1PqK5",
        "outputId": "e3b1edad-6d13-40db-fcfa-c799607462c7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Name                        Desc Runs Balls 4s 6s      SR Team\n",
              "0      Rohit Sharma           c Rayudu b Watson   15    18  1  1   83.33    1\n",
              "1        Evin Lewis                lbw b Chahar    0     2  0  0    0.00    1\n",
              "2      Ishan Kishan        c Wood b Imran Tahir   40    29  4  1  137.93    1\n",
              "3  Suryakumar Yadav  c Harbhajan Singh b Watson   43    29  6  1  148.27    1\n",
              "4     Hardik Pandya                     not out   22    20  2  0  110.00    1\n",
              "5      Shane Watson         c Lewis b HH Pandya   16    14  1  1  114.28    2\n",
              "6     Ambati Rayudu              lbw b Markande   22    19  4  0  115.78    2\n",
              "7      Suresh Raina     c KH Pandya b HH Pandya    4     6  0  0   66.66    2\n",
              "8      Kedar Jadhav                     not out   24    22  1  2  109.09    2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fd242d0-8d7c-4f8a-a9dc-f6fd7b94703e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Desc</th>\n",
              "      <th>Runs</th>\n",
              "      <th>Balls</th>\n",
              "      <th>4s</th>\n",
              "      <th>6s</th>\n",
              "      <th>SR</th>\n",
              "      <th>Team</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rohit Sharma</td>\n",
              "      <td>c Rayudu b Watson</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>83.33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Evin Lewis</td>\n",
              "      <td>lbw b Chahar</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ishan Kishan</td>\n",
              "      <td>c Wood b Imran Tahir</td>\n",
              "      <td>40</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>137.93</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Suryakumar Yadav</td>\n",
              "      <td>c Harbhajan Singh b Watson</td>\n",
              "      <td>43</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>148.27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hardik Pandya</td>\n",
              "      <td>not out</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>110.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Shane Watson</td>\n",
              "      <td>c Lewis b HH Pandya</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>114.28</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ambati Rayudu</td>\n",
              "      <td>lbw b Markande</td>\n",
              "      <td>22</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>115.78</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Suresh Raina</td>\n",
              "      <td>c KH Pandya b HH Pandya</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>66.66</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Kedar Jadhav</td>\n",
              "      <td>not out</td>\n",
              "      <td>24</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>109.09</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fd242d0-8d7c-4f8a-a9dc-f6fd7b94703e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5fd242d0-8d7c-4f8a-a9dc-f6fd7b94703e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5fd242d0-8d7c-4f8a-a9dc-f6fd7b94703e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3c31a42b-8c4e-4cef-8044-31eb39187e4b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c31a42b-8c4e-4cef-8044-31eb39187e4b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3c31a42b-8c4e-4cef-8044-31eb39187e4b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"extract_batting_data(series_id=8048, match_id=1136561)\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Suresh Raina\",\n          \"Evin Lewis\",\n          \"Shane Watson\"\n        ],\n        \"num_unique_values\": 9,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Desc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"lbw b Chahar\",\n          \"c Lewis b HH Pandya\",\n          \"c Rayudu b Watson\"\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Runs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"0\",\n          \"16\",\n          \"15\"\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"2\",\n          \"19\",\n          \"18\"\n        ],\n        \"num_unique_values\": 8,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"4s\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"0\",\n          \"2\",\n          \"4\"\n        ],\n        \"num_unique_values\": 5,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"6s\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"1\",\n          \"0\",\n          \"2\"\n        ],\n        \"num_unique_values\": 3,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SR\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"66.66\",\n          \"0.00\",\n          \"114.28\"\n        ],\n        \"num_unique_values\": 9,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Team\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03jb4GZsBkBS"
      },
      "source": [
        "## Question 3 (10 Points)\n",
        "Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n",
        "\n",
        "The following information from the article needs to be collected:\n",
        "\n",
        "(1) Title of the article\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YaGLbSHHB8Ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772a05ad-4158-46a5-fcf6-f07842b33f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://dl.acm.org/action/doSearch?AllField=nlp&startPage=&AfterYear=2014&BeforeYear=2023&queryID=3/6579449608\n",
            "Title :  Natural language processing (NLP) applied on issue trackers\n",
            "Author :  Mathias Ellmann\n",
            "Citation :  short-paperNovember 2018Published By ACM\n",
            "Year :  November 2018\n",
            "Abstract :  Natural language processing (NLP) applied on issue trackersMathias EllmannNL4SE 2018: Proceedings of the 4th ACM SIGSOFT International Workshop on NLP for Software EngineeringNovember 2018, pp 38–41https://doi.org/10.1145/3283812.3283825\n",
            "In the domain of software engineering NLP techniques are needed to use and find duplicate or similar development knowledge which are stored in development documentation as development tasks. To understand duplicate and similar development documentations ...6561MetricsTotal Citations6Total Downloads561Last 12 Months78Last 6 weeks4/action/highlight?doi=10.1145%2F3283812.3283825&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  Extracting meaning from text and creating a custom language model to optimize NLP results: NLP hands-on workshop series\n",
            "Author :  Sarah Packowski,Wendy Switzer\n",
            "Citation :  research-articleNovember 2019\n",
            "Year :  November 2019\n",
            "Abstract :  Extracting meaning from text and creating a custom language model to optimize NLP results: NLP hands-on workshop seriesSarah Packowski,Wendy SwitzerCASCON '19: Proceedings of the 29th Annual International Conference on Computer Science and Software EngineeringNovember 2019, pp 382–383\n",
            "The use of Natural Language Processing (NLP) is becoming common: - Social media - Customer-service \"bots\" - Automatic captioning - Cognitive-enhanced search - Applications for school, jobs, or loans - Health monitoring - Legal processes - Law ...0184MetricsTotal Citations0Total Downloads184Last 12 Months26Last 6 weeks5/action/highlight?doi=10.5555%2F3370272.3370327&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  Quran content representation in NLP\n",
            "Author :  Zineb Touati-Hamad,Mohamed Ridda Laouar,Issam Bendib\n",
            "Citation :  research-articleMarch 2021Published By ACM\n",
            "Year :  March 2021\n",
            "Abstract :  Quran content representation in NLPZineb Touati-Hamad,Mohamed Ridda Laouar,Issam BendibICIST '20: Proceedings of the 10th International Conference on Information Systems and TechnologiesJune 2020, Article No.: 44, pp 1–6https://doi.org/10.1145/3447568.3448552\n",
            "Word representation is a starting point for Natural Language Processing (NLP). These representations transform words into symbolic vectors of a given length that reveal the hidden linguistic and semantic similarities. This paper presents a study of the ...1105MetricsTotal Citations1Total Downloads105Last 12 Months34Last 6 weeks5/action/highlight?doi=10.1145%2F3447568.3448552&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  IR meets NLP: On the Semantic Similarity between Subject-Verb-Object Phrases\n",
            "Author :  Dmitrijs Milajevs,Mehrnoosh Sadrzadeh,Thomas Roelleke\n",
            "Citation :  research-articleSeptember 2015Published By ACM\n",
            "Year :  September 2015\n",
            "Abstract :  IR meets NLP: On the Semantic Similarity between Subject-Verb-Object PhrasesDmitrijs Milajevs,Mehrnoosh Sadrzadeh,Thomas RoellekeICTIR '15: Proceedings of the 2015 International Conference on The Theory of Information RetrievalSeptember 2015, pp 231–240https://doi.org/10.1145/2808194.2809448\n",
            "Measuring the semantic similarity between phrases and sentences is an important task in natural language processing (NLP) and information retrieval (IR). We compare the quality of the distributional semantic NLP models against phrase-based semantic IR. ...3292MetricsTotal Citations3Total Downloads292Last 12 Months15Last 6 weeks1/action/highlight?doi=10.1145%2F2808194.2809448&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  A Neural NLP toolkit for Greek\n",
            "Author :  Prokopis Prokopidis,Stelios Piperidis\n",
            "Citation :  short-paperSeptember 2020Published By ACM\n",
            "Year :  September 2020\n",
            "Abstract :  A Neural NLP toolkit for GreekProkopis Prokopidis,Stelios PiperidisSETN 2020: 11th Hellenic Conference on Artificial IntelligenceSeptember 2020, pp 125–128https://doi.org/10.1145/3411408.3411430\n",
            "We present a neural NLP toolkit for Greek, currently integrating modules for POS tagging, lemmatization, dependency parsing and text classification. The toolkit is based on language resources including web crawled corpora, word embeddings, large lexica, ...6204MetricsTotal Citations6Total Downloads204Last 12 Months50Last 6 weeks6/action/highlight?doi=10.1145%2F3411408.3411430&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  A Survey of Adversarial Defenses and Robustness in NLP\n",
            "Author :  Shreya Goyal,Sumanth Doddapaneni,Mitesh M. Khapra,Balaraman Ravindran\n",
            "Citation :  surveyJuly 2023Published By ACM\n",
            "Year :  July 2023\n",
            "Abstract :  A Survey of Adversarial Defenses and Robustness in NLPShreya Goyal,Sumanth Doddapaneni,Mitesh M. Khapra,Balaraman RavindranACM Computing Surveys (CSUR), Volume 55, Issue 14sArticle No.: 332, pp 1–39https://doi.org/10.1145/3593042In the past few years, it has become increasingly evident that deep neural networks are not resilient enough to withstand adversarial perturbations in input data, leaving them vulnerable to attack. Various authors have proposed strong adversarial attacks ...22,181MetricsTotal Citations2Total Downloads2,181Last 12 Months2,181Last 6 weeks482/action/highlight?doi=10.1145%2F3593042&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  NLP Cross-Domain Recognition of Retail Products\n",
            "Author :  Tobias Pettersson,Rachid Oucheikh,Tuwe Lofstrom\n",
            "Citation :  research-articleOpen AccessJune 2022Published By ACM\n",
            "Year :  June 2022\n",
            "Abstract :  NLP Cross-Domain Recognition of Retail ProductsTobias Pettersson,Rachid Oucheikh,Tuwe LofstromICMLT '22: Proceedings of the 2022 7th International Conference on Machine Learning TechnologiesMarch 2022, pp 237–243https://doi.org/10.1145/3529399.3529436\n",
            " Self‐checkout systems aim to provide a seamless and high-quality shopping experience and increase the profitability of stores. These advantages come with some challenges such as shrinkage loss. To overcome these challenges, automatic recognition of the ...1331MetricsTotal Citations1Total Downloads331Last 12 Months215Last 6 weeks25/action/highlight?doi=10.1145%2F3529399.3529436&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                View online with eReaderHTMLPDF\n",
            "\n",
            "\n",
            "Title :  The 6th Workshop on e-eommerce and NLP (ECNLP 6)\n",
            "Author :  Shervin Malmasi,Besnik Fetahu,Eugene Agichtein,Oleg Rokhlenko,Ido Guy,Nicola Ueffing,Surya Kallumadi\n",
            "Citation :  abstractAugust 2023Published By ACM\n",
            "Year :  August 2023\n",
            "Abstract :  The 6th Workshop on e-eommerce and NLP (ECNLP 6)Shervin Malmasi,Besnik Fetahu,Eugene Agichtein,Oleg Rokhlenko,Ido Guy,Nicola Ueffing,Surya KallumadiKDD '23: Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data MiningAugust 2023, pp 5872–5873https://doi.org/10.1145/3580305.3599212\n",
            "Natural Language Processing (NLP) technology plays a key role in e-commerce today, where this technology can be used for a range of tasks, such as improving search results, providing recommendations, and powering virtual assistants. The ECNLP workshop ...089MetricsTotal Citations0Total Downloads89Last 12 Months89Last 6 weeks10/action/highlight?doi=10.1145%2F3580305.3599212&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  Does reusing pre-trained NLP model propagate bugs?\n",
            "Author :  Mohna Chakraborty\n",
            "Citation :  short-paperOpen AccessAugust 2021Published By ACM\n",
            "Year :  August 2021\n",
            "Abstract :  Does reusing pre-trained NLP model propagate bugs?Mohna ChakrabortyESEC/FSE 2021: Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software EngineeringAugust 2021, pp 1686–1688https://doi.org/10.1145/3468264.3473494\n",
            "In this digital era, the textual content has become a seemingly ubiquitous part of our life. Natural Language Processing (NLP) empowers machines to comprehend the intricacies of textual data and eases human-computer interaction. Advancement in language ...0398MetricsTotal Citations0Total Downloads398Last 12 Months105Last 6 weeks7/action/highlight?doi=10.1145%2F3468264.3473494&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                View online with eReaderPDF\n",
            "\n",
            "\n",
            "Title :  Integrating NLP with Corpus Linguistics and Vice Versa\n",
            "Author :  Sultan Almujaiwel\n",
            "Citation :  research-articleMay 2018Published By ACM\n",
            "Year :  May 2018\n",
            "Abstract :  Integrating NLP with Corpus Linguistics and Vice VersaSultan AlmujaiwelLOPAL '18: Proceedings of the International Conference on Learning and Optimization Algorithms: Theory and ApplicationsMay 2018, Article No.: 38, pp 1–6https://doi.org/10.1145/3230905.3230930\n",
            "This paper is a call to bring Natural Language Processing (NLP) and Corpus Linguistics (CL) together in order to promote more effective linguistic research. Arabic NLP has recently come up with a significant number of techniques and methods that help to ...084MetricsTotal Citations0Total Downloads84Last 12 Months5Last 6 weeks1/action/highlight?doi=10.1145%2F3230905.3230930&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  Examining risks of racial biases in NLP tools for child protective services\n",
            "Author :  Anjalie Field,Amanda Coston,Nupoor Gandhi,Alexandra Chouldechova,Emily Putnam-Hornstein,David Steier,Yulia Tsvetkov\n",
            "Citation :  research-articleOpen AccessJune 2023Published By ACM\n",
            "Year :  June 2023\n",
            "Abstract :  Examining risks of racial biases in NLP tools for child protective servicesAnjalie Field,Amanda Coston,Nupoor Gandhi,Alexandra Chouldechova,Emily Putnam-Hornstein,David Steier,Yulia TsvetkovFAccT '23: Proceedings of the 2023 ACM Conference on Fairness, Accountability, and TransparencyJune 2023, pp 1479–1492https://doi.org/10.1145/3593013.3594094  Although much literature has established the presence of demographic bias in natural language processing (NLP) models, most work relies on curated bias metrics that may not be reflective of real-world applications. At the same time, practitioners are ...0717MetricsTotal Citations0Total Downloads717Last 12 Months717Last 6 weeks130/action/highlight?doi=10.1145%2F3593013.3594094&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                View online with eReaderHTMLPDF\n",
            "\n",
            "\n",
            "Title :  BadNL: Backdoor Attacks against NLP Models with Semantic-preserving Improvements\n",
            "Author :  Xiaoyi Chen,Ahmed Salem,Dingfan Chen,Michael Backes,Shiqing Ma,Qingni Shen,Zhonghai Wu,Yang Zhang\n",
            "Citation :  research-articleDecember 2021Published By ACM\n",
            "Year :  December 2021\n",
            "Abstract :  BadNL: Backdoor Attacks against NLP Models with Semantic-preserving ImprovementsXiaoyi Chen,Ahmed Salem,Dingfan Chen,Michael Backes,Shiqing Ma,Qingni Shen,Zhonghai Wu,Yang ZhangACSAC '21: Proceedings of the 37th Annual Computer Security Applications ConferenceDecember 2021, pp 554–569https://doi.org/10.1145/3485832.3485837\n",
            " Deep neural networks (DNNs) have progressed rapidly during the past decade and have been deployed in various real-world applications. Meanwhile, DNN models have been shown to be vulnerable to security and privacy attacks. One such attack that has ...25880MetricsTotal Citations25Total Downloads880Last 12 Months414Last 6 weeks51/action/highlight?doi=10.1145%2F3485832.3485837&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  DeepLens: Interactive Out-of-distribution Data Detection in NLP Models\n",
            "Author :  Da Song,Zhijie Wang,Yuheng Huang,Lei Ma,Tianyi Zhang\n",
            "Citation :  research-articleApril 2023Published By ACM\n",
            "Year :  April 2023\n",
            "Abstract :  DeepLens: Interactive Out-of-distribution Data Detection in NLP ModelsDa Song,Zhijie Wang,Yuheng Huang,Lei Ma,Tianyi ZhangCHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing SystemsApril 2023, Article No.: 739, pp 1–17https://doi.org/10.1145/3544548.3580741\n",
            "Machine Learning (ML) has been widely used in Natural Language Processing (NLP) applications. A fundamental assumption in ML is that training data and real-world data should follow a similar distribution. However, a deployed ML model may suffer from out-...0294MetricsTotal Citations0Total Downloads294Last 12 Months294Last 6 weeks273Supplementary Material3544548.3580741-talk-video.mp43544548.3580741-video-preview.mp43544548.3580741-video-figure.mp4/action/highlight?doi=10.1145%2F3544548.3580741&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  Combining NLP And Semantics For Mining Software Technologies From Research Publications\n",
            "Author :  Hélène de Ribaupierre,Francesco Osborne,Enrico Motta\n",
            "Citation :  posterApril 2016\n",
            "Year :  April 2016\n",
            "Abstract :  Combining NLP And Semantics For Mining Software Technologies From Research PublicationsHélène de Ribaupierre,Francesco Osborne,Enrico MottaWWW '16 Companion: Proceedings of the 25th International Conference Companion on World Wide WebApril 2016, pp 23–24https://doi.org/10.1145/2872518.2889358\n",
            "The natural language processing (NLP) community has developed a variety of methods for extracting and disambiguating information from research publications. However, they usually focus only on standard research entities such as authors, affiliations, ...1157MetricsTotal Citations1Total Downloads157Last 12 Months4Last 6 weeks1/action/highlight?doi=10.1145%2F2872518.2889358&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  Opening the NLP Blackbox - Analysis and Evaluation of NLP Models: Methods, Challenges and Opportunities\n",
            "Author :  Sandya Mannarswamy,Saravanan Chidambaram\n",
            "Citation :  tutorialJanuary 2021Published By ACM\n",
            "Year :  January 2021\n",
            "Abstract :  Opening the NLP Blackbox - Analysis and Evaluation of NLP Models: Methods, Challenges and OpportunitiesSandya Mannarswamy,Saravanan ChidambaramCODS-COMAD '21: Proceedings of the 3rd ACM India Joint International Conference on Data Science & Management of Data (8th ACM IKDD CODS & 26th COMAD)January 2021, pp 447–448https://doi.org/10.1145/3430984.3431969\n",
            "Although Rapid progress in NLP Research has seen a swift translation to real world commercial deployment. While a number of NLP applications have emerged, failures of translating scientific progress in NLP to real-world software have also been ...2162MetricsTotal Citations2Total Downloads162Last 12 Months31Last 6 weeks7/action/highlight?doi=10.1145%2F3430984.3431969&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  A Novel NLP Application to Automatically Generate Text Extraction Concepts from Textual Descriptions\n",
            "Author :  Imran Ahsan,Mudassar Adeel Ahmed,Saad Rehman,Muhammad Abbas,Muazzam A. Khan\n",
            "Citation :  research-articleApril 2019Published By ACM\n",
            "Year :  April 2019\n",
            "Abstract :  A Novel NLP Application to Automatically Generate Text Extraction Concepts from Textual DescriptionsImran Ahsan,Mudassar Adeel Ahmed,Saad Rehman,Muhammad Abbas,Muazzam A. KhanICCAI '19: Proceedings of the 2019 5th International Conference on Computing and Artificial IntelligenceApril 2019, pp 55–58https://doi.org/10.1145/3330482.3330506\n",
            "Text summarization has become a sophisticated approach for the quick searching, automatic sorting, abstract generating etc., to the large amount of data. The involvement of complete study of passage and extra time is needed to generate the essence of ...0258MetricsTotal Citations0Total Downloads258Last 12 Months13Last 6 weeks4/action/highlight?doi=10.1145%2F3330482.3330506&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  Multimodality-aware Intra-dialytic Hypotension Classifier: A Bilingual NLP Approach to Classify Dialysis Records\n",
            "Author :  Ju-Yeh Yang,Tsung-Chun Lee,Chih-Yu Jian,Chih-Chung Hsu\n",
            "Citation :  abstractOctober 2023Published By ACM\n",
            "Year :  October 2023\n",
            "Abstract :  Multimodality-aware Intra-dialytic Hypotension Classifier: A Bilingual NLP Approach to Classify Dialysis RecordsJu-Yeh Yang,Tsung-Chun Lee,Chih-Yu Jian,Chih-Chung HsuBCB '23: Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health InformaticsSeptember 2023, Article No.: 82, pp 1https://doi.org/10.1145/3584371.3613054\n",
            "Nursing records, rich in free-text data, encapsulate valuable insights into patients' physiological status and physicians' diagnoses, offering more holistic perspectives than mere tabular data. The scrutiny of these free-text descriptions often ...09MetricsTotal Citations0Total Downloads9Last 12 Months9Last 6 weeks1/action/highlight?doi=10.1145%2F3584371.3613054&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  Generating UML Use Case and Activity Diagrams Using NLP Techniques and Heuristics Rules\n",
            "Author :  Abdelsalam M. Maatuk,Esra A. Abdelnabi\n",
            "Citation :  research-articleJune 2021Published By ACM\n",
            "Year :  June 2021\n",
            "Abstract :  Generating UML Use Case and Activity Diagrams Using NLP Techniques and Heuristics RulesAbdelsalam M. Maatuk,Esra A. AbdelnabiDATA'21: International Conference on Data Science, E-learning and Information Systems 2021April 2021, pp 271–277https://doi.org/10.1145/3460620.3460768\n",
            "The process of generating Unified Modeling Language (UML) Diagrams from Natural Language (NL) requirements is considered a complex and challenging task. Software requirements specification is often written in NL format, which causes potential problems. ...3391MetricsTotal Citations3Total Downloads391Last 12 Months137Last 6 weeks12/action/highlight?doi=10.1145%2F3460620.3460768&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n",
            "Title :  Autograding \"Explain in Plain English\" questions using NLP\n",
            "Author :  Max Fowler,Binglin Chen,Sushmita Azad,Matthew West,Craig Zilles\n",
            "Citation :  ArticlePublic AccessMarch 2021Published By ACM\n",
            "Year :  March 2021\n",
            "Abstract :  Autograding \"Explain in Plain English\" questions using NLPMax Fowler,Binglin Chen,Sushmita Azad,Matthew West,Craig ZillesSIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science EducationMarch 2021, pp 1163–1169https://doi.org/10.1145/3408877.3432539\n",
            "Previous research suggests that \"Explain in Plain English\" (EiPE) code reading activities could play an important role in the development of novice programmers, but EiPE questions aren't heavily used in introductory programming courses because they (...9732MetricsTotal Citations9Total Downloads732Last 12 Months264Last 6 weeks26/action/highlight?doi=10.1145%2F3408877.3432539&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                View online with eReaderPDF\n",
            "\n",
            "\n",
            "Title :  Assistance System for Judicial Awards for The Colombian State Legal Defense Agency Through NLP -ANDJE-\n",
            "Author :  Jose Armando Hernandez Gonzalez\n",
            "Citation :  research-articleMarch 2023Published By ACM\n",
            "Year :  March 2023\n",
            "Abstract :  Assistance System for Judicial Awards for The Colombian State Legal Defense Agency Through NLP -ANDJE-Jose Armando Hernandez GonzalezMLNLP '22: Proceedings of the 2022 5th International Conference on Machine Learning and Natural Language ProcessingDecember 2022, pp 258–265https://doi.org/10.1145/3578741.3578793\n",
            "The present work proposes a legal assistance tool based on NLP and a predictive ML model adapted to the particularities of Colombian Justice system for the Legal Defense Agency of the Colombian State (ANDJE), It is developed in 4 parts associated with ...011MetricsTotal Citations0Total Downloads11Last 12 Months11Last 6 weeks1/action/highlight?doi=10.1145%2F3578741.3578793&query=nlpHighlightsExport CitationsSave to BinderSave to Binder\n",
            "                                    Create a New Binder\n",
            "                                NameCancel\n",
            "                                                \n",
            "                                                    Create\n",
            "                                                Get Access\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "keyword = \"NLP\"\n",
        "years_range = range(2014, 2025)\n",
        "\n",
        "url = f\"https://dl.acm.org/action/doSearch?AllField={keyword.lower()}&startPage=&AfterYear={min(years_range)}&BeforeYear={max(years_range) - 1}&queryID=3/6579449608\"\n",
        "\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "parent_div = soup.find(\"div\", class_=\"issue-item__content\")\n",
        "\n",
        "articles = soup.select(\".issue-item.issue-item--search.clearfix\")\n",
        "\n",
        "\n",
        "for article in articles:\n",
        "  print(\"Title : \", article.select_one(\".issue-item__title\").get_text().strip())\n",
        "  print(\"Author : \", article.select_one(\"ul\").get_text().strip()) if (ul := article.select_one(\"ul\")) else None; list_items = [li.get_text() for li in ul.find_all(\"li\")] if ul else None\n",
        "  print(\"Citation : \", article.select_one(\".issue-item__citation\").get_text().strip())\n",
        "  print(\"Year : \", article.select_one(\".bookPubDate.simple-tooltip__block--b\").get_text().strip())\n",
        "  print(\"Abstract : \", article.select_one(\".issue-item__content-right\").get_text().strip())\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print(articles)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDe71iLB616"
      },
      "source": [
        "## Question 4A (10 Points)\n",
        "Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n",
        "\n",
        "\n",
        "\n",
        "Ensure that the collected data has more than four columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtKskTzbCLaU"
      },
      "outputs": [],
      "source": [
        "# write your answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55W9AMdXCSpV"
      },
      "source": [
        "## Question 4B (10 Points)\n",
        "If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n",
        "\n",
        "\n",
        "\n",
        "Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n",
        "\n",
        "Please only choose one option for question 4. If you do both options, we will grade only the first one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "I57NXsauCec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a6e10002-0be6-402a-8eea-e2eaaca0b2ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nHere i've used a tool called Data Scrapper where, we have to use it in the desired website to select all the data needed,\\nindex them, modify according to our needs and then we have to seect no of pages like kind of parsing the next page or dealing\\nin the same page. when you are done with it, you have to click on start, it  compiles, scraps data from website, and produces\\nresults, where you will have to opt whether to store as excel or csv format. and download the data.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# write your answer here\n",
        "\"\"\"\n",
        "Here i've used a tool called Data Scrapper where, we have to use it in the desired website to select all the data needed,\n",
        "index them, modify according to our needs and then we have to seect no of pages like kind of parsing the next page or dealing\n",
        "in the same page. when you are done with it, you have to click on start, it  compiles, scraps data from website, and produces\n",
        "results, where you will have to opt whether to store as excel or csv format. and download the data.\"\"\"\n",
        "#the data set downloaded by scraping website ESPNcricinfo stats is stored in below csv file:\n",
        "# https://drive.google.com/file/d/18Q9ICKVLzBdfRLgGtVm44e4gUJXefmAJ/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "sZOhks1dXWEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on Web Scraping and Data Collection**\n",
        "\n",
        "\n",
        "\n",
        "Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n",
        "\n",
        "\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n",
        "\n",
        "\n",
        "\n",
        "Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n",
        "\n",
        "**(no grading of your submission if this question is left unanswered)**"
      ],
      "metadata": {
        "id": "eqmHVEwaWhbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Learning Experience: I found webscapping quite difficult as i faced problems like google blocking me from attempting multiple requests ,\n",
        "i aslo faced problems while inspecting the page and looking forparticular Element, class ids of the target data.\n",
        "But it is very much fun using web scrapping tools or extensions like data Scrapper which i used to solve question 4B.\n",
        "Although i faced problems, i found a way to  overcome them in few instances and left the rest as time's not enough.\n",
        "I still need to learn, put efforts to learn webscrapping.\n",
        "\n",
        "Chllenges Encountered: inspecting webpage for particular class_id, getting data from websites is not as easy as i thought,\n",
        "blockage by google while attempting scrap from google scholar, not enought time for this assignment as scrapping took lot of time.\n",
        "\n",
        "Relevance to My Field of Study : I've worked on collecting data from websites using automation tools, but never worked on manual scrapping. It is relavent to me and there's need for me to learn this as i may encounter such problems in future as my field includes dealing with such data. So this is very important for me to learn and will focus on this in the coming time. Glad that this is part of course and showed us how important it is to scrap web data\n",
        "Write your response here.\n",
        "'''"
      ],
      "metadata": {
        "id": "akAVJn9YBTQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "31adf743-8889-481b-9625-0a286858279a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nLearning Experience: I found webscapping quite difficult as i faced problems like google blocking me from attempting multiple requests , \\ni aslo faced problems while inspecting the page and looking forparticular Element, class ids of the target data.\\nBut it is very much fun using web scrapping tools or extensions like data Scrapper which i used to solve question 4B. \\nAlthough i faced problems, i found a way to  overcome them in few instances and left the rest as time's not enough.\\nI still need to learn, put efforts to learn webscrapping.\\n\\nChllenges Encountered: inspecting webpage for particular class_id, getting data from websites is not as easy as i thought, \\nblockage by google while attempting scrap from google scholar, not enought time for this assignment as scrapping took lot of time.\\n\\nRelevance to My Field of Study : I've worked on collecting data from websites using automation tools, but never worked on manual scrapping. It is relavent to me and there's need for me to learn this as i may encounter such problems in future as my field includes dealing with such data. So this is very important for me to learn and will focus on this in the coming time. Glad that this is part of course and showed us how important it is to scrap web data\\nWrite your response here.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6oLb_N-SD0Wp"
      },
      "execution_count": 4,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FBKvD6O_TY6e",
        "E9RqrlwdTfvl",
        "03jb4GZsBkBS",
        "jJDe71iLB616",
        "55W9AMdXCSpV",
        "4ulBZ6yhCi9F",
        "6SmvS7nSfbj8",
        "sZOhks1dXWEe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}